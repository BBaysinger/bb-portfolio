name: Redeploy (Manual)

on:
  workflow_dispatch:
    inputs:
      environment:
        description: Which profiles to (re)start
        type: choice
        required: true
        default: both
        options: [prod, dev, both]
      start_dev:
        description: Ensure dev containers are up in addition to prod
        type: choice
        required: true
        default: "true"
        options: ["true", "false"]
      refresh_env:
        description: Regenerate and upload .env files to EC2 (requires secrets)
        type: choice
        required: true
        default: "false"
        options: ["true", "false"]
      restart_containers:
        description: Restart containers on EC2 (docker-compose pull/up)
        type: choice
        required: true
        default: "true"
        options: ["true", "false"]

permissions:
  contents: read
  actions: read

jobs:
  sanity:
    runs-on: ubuntu-latest
    steps:
      - name: Print inputs
        run: |
          echo "environment=${{ inputs.environment }}"
          echo "start_dev=${{ inputs.start_dev }}"
          echo "refresh_env=${{ inputs.refresh_env }}"
          echo "restart_containers=${{ inputs.restart_containers }}"
  deploy:
    name: SSH redeploy on EC2 (manual)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    concurrency:
      group: redeploy-${{ inputs.environment == 'both' && 'global' || inputs.environment }}
      cancel-in-progress: true
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare SSH key
        id: ssh
        env:
          SSH_KEY_PEM: ${{ secrets.EC2_SSH_KEY_PEM }}
          SSH_KEY_ALT: ${{ secrets.EC2_SSH_KEY }}
        run: |
          set -euo pipefail
          CONTENT="${SSH_KEY_PEM:-}"
          if [ -z "$CONTENT" ] && [ -n "${SSH_KEY_ALT:-}" ]; then
            CONTENT="$SSH_KEY_ALT"
          fi
          if [ -z "$CONTENT" ]; then
            echo "Missing SSH key secret: provide EC2_SSH_KEY_PEM or EC2_SSH_KEY" >&2
            exit 1
          fi
          umask 177
          printf "%s" "$CONTENT" > key.pem
          echo "key=key.pem" >> "$GITHUB_OUTPUT"

      - name: Validate required inputs and secrets
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          REFRESH_ENV: ${{ inputs.refresh_env }}
          PROD_MONGODB_URI: ${{ secrets.PROD_MONGODB_URI }}
          PROD_PAYLOAD_SECRET: ${{ secrets.PROD_PAYLOAD_SECRET }}
          PROD_S3_BUCKET: ${{ secrets.PROD_S3_BUCKET }}
          PROD_AWS_REGION: ${{ secrets.PROD_AWS_REGION }}
          DEV_MONGODB_URI: ${{ secrets.DEV_MONGODB_URI }}
          DEV_PAYLOAD_SECRET: ${{ secrets.DEV_PAYLOAD_SECRET }}
          DEV_S3_BUCKET: ${{ secrets.DEV_S3_BUCKET }}
          DEV_AWS_REGION: ${{ secrets.DEV_AWS_REGION }}
        run: |
          set -euo pipefail
          : "${ENVIRONMENT}"
          : "${EC2_HOST}"
          : "${REFRESH_ENV}"
          # Only enforce env-specific secrets for the selected environment(s)
          if [ "$REFRESH_ENV" = "true" ]; then
            case "$ENVIRONMENT" in
              prod)
                : "${PROD_MONGODB_URI}"
                : "${PROD_PAYLOAD_SECRET}"
                : "${PROD_S3_BUCKET}"
                : "${PROD_AWS_REGION}"
                ;;
              dev)
                : "${DEV_MONGODB_URI}"
                : "${DEV_PAYLOAD_SECRET}"
                : "${DEV_S3_BUCKET}"
                : "${DEV_AWS_REGION}"
                ;;
              both)
                : "${PROD_MONGODB_URI}"
                : "${PROD_PAYLOAD_SECRET}"
                : "${PROD_S3_BUCKET}"
                : "${PROD_AWS_REGION}"
                : "${DEV_MONGODB_URI}"
                : "${DEV_PAYLOAD_SECRET}"
                : "${DEV_S3_BUCKET}"
                : "${DEV_AWS_REGION}"
                ;;
            esac
          fi

      - name: Generate env files (in runner temp)
        id: genenv
        if: ${{ inputs.refresh_env == 'true' || inputs.refresh_env == true }}
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          # Common
          S3_REGION: ${{ secrets.S3_REGION }}
          # Prod
          PROD_MONGODB_URI: ${{ secrets.PROD_MONGODB_URI }}
          PROD_PAYLOAD_SECRET: ${{ secrets.PROD_PAYLOAD_SECRET }}
          PROD_S3_BUCKET: ${{ secrets.PROD_S3_BUCKET }}
          PROD_AWS_REGION: ${{ secrets.PROD_AWS_REGION }}
          PROD_FRONTEND_URL: ${{ secrets.PROD_FRONTEND_URL }}
          PROD_BACKEND_INTERNAL_URL: ${{ secrets.PROD_BACKEND_INTERNAL_URL }}
          PROD_SES_FROM_EMAIL: ${{ secrets.PROD_SES_FROM_EMAIL }}
          PROD_SES_TO_EMAIL: ${{ secrets.PROD_SES_TO_EMAIL }}
          # Dev
          DEV_MONGODB_URI: ${{ secrets.DEV_MONGODB_URI }}
          DEV_PAYLOAD_SECRET: ${{ secrets.DEV_PAYLOAD_SECRET }}
          DEV_S3_BUCKET: ${{ secrets.DEV_S3_BUCKET }}
          DEV_AWS_REGION: ${{ secrets.DEV_AWS_REGION }}
          DEV_FRONTEND_URL: ${{ secrets.DEV_FRONTEND_URL }}
          DEV_BACKEND_INTERNAL_URL: ${{ secrets.DEV_BACKEND_INTERNAL_URL }}
          DEV_SES_FROM_EMAIL: ${{ secrets.DEV_SES_FROM_EMAIL }}
          DEV_SES_TO_EMAIL: ${{ secrets.DEV_SES_TO_EMAIL }}
        run: |
          set -euo pipefail
          OUT_DIR="$(mktemp -d)"

          s_val() { [ -n "${!1:-}" ] && echo "${!1}" || echo "${2:-}"; }

          # Write files using printf to avoid heredoc/YAML indentation pitfalls
          printf "%s\n" \
            "NODE_ENV=production" \
            "ENV_PROFILE=prod" \
            "" \
            "PROD_AWS_REGION=$(s_val PROD_AWS_REGION \"$S3_REGION\")" \
            "" \
            "PROD_MONGODB_URI=$(s_val PROD_MONGODB_URI)" \
            "PROD_PAYLOAD_SECRET=$(s_val PROD_PAYLOAD_SECRET)" \
            "" \
            "PROD_S3_BUCKET=$(s_val PROD_S3_BUCKET)" \
            "S3_REGION=$(s_val S3_REGION \"$PROD_AWS_REGION\")" \
            "" \
            "PROD_FRONTEND_URL=$(s_val PROD_FRONTEND_URL)" \
            "PROD_BACKEND_INTERNAL_URL=$(s_val PROD_BACKEND_INTERNAL_URL 'http://bb-portfolio-backend-prod:3000')" \
            "" \
            "PROD_SES_FROM_EMAIL=$(s_val PROD_SES_FROM_EMAIL)" \
            "PROD_SES_TO_EMAIL=$(s_val PROD_SES_TO_EMAIL)" \
            > "$OUT_DIR/backend.env.prod"

          printf "%s\n" \
            "NODE_ENV=development" \
            "ENV_PROFILE=dev" \
            "" \
            "DEV_AWS_REGION=$(s_val DEV_AWS_REGION \"$S3_REGION\")" \
            "" \
            "DEV_MONGODB_URI=$(s_val DEV_MONGODB_URI)" \
            "DEV_PAYLOAD_SECRET=$(s_val DEV_PAYLOAD_SECRET)" \
            "" \
            "DEV_S3_BUCKET=$(s_val DEV_S3_BUCKET)" \
            "S3_REGION=$(s_val S3_REGION \"$DEV_AWS_REGION\")" \
            "" \
            "DEV_FRONTEND_URL=$(s_val DEV_FRONTEND_URL)" \
            "DEV_BACKEND_INTERNAL_URL=$(s_val DEV_BACKEND_INTERNAL_URL 'http://bb-portfolio-backend-dev:3000')" \
            "" \
            "DEV_SES_FROM_EMAIL=$(s_val DEV_SES_FROM_EMAIL)" \
            "DEV_SES_TO_EMAIL=$(s_val DEV_SES_TO_EMAIL)" \
            > "$OUT_DIR/backend.env.dev"

          printf "%s\n" \
            "NODE_ENV=production" \
            "ENV_PROFILE=prod" \
            > "$OUT_DIR/frontend.env.prod"

          printf "%s\n" \
            "NODE_ENV=development" \
            "ENV_PROFILE=dev" \
            > "$OUT_DIR/frontend.env.dev"

          echo "dir=$OUT_DIR" >> "$GITHUB_OUTPUT"

      - name: Upload env files to EC2
        if: ${{ inputs.refresh_env == 'true' || inputs.refresh_env == true }}
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          OUT_DIR='${{ steps.genenv.outputs.dir }}'
          test -n "$OUT_DIR" && test -d "$OUT_DIR"

          # Prepare remote directories
          ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" "mkdir -p /home/ec2-user/portfolio/backend /home/ec2-user/portfolio/frontend"

          scp -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            "$OUT_DIR/backend.env.prod"  ec2-user@"$EC2_HOST":/home/ec2-user/portfolio/backend/.env.prod
          scp -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            "$OUT_DIR/backend.env.dev"   ec2-user@"$EC2_HOST":/home/ec2-user/portfolio/backend/.env.dev
          scp -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            "$OUT_DIR/frontend.env.prod" ec2-user@"$EC2_HOST":/home/ec2-user/portfolio/frontend/.env.prod
          scp -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            "$OUT_DIR/frontend.env.dev"  ec2-user@"$EC2_HOST":/home/ec2-user/portfolio/frontend/.env.dev

      - name: Restart containers
        if: ${{ inputs.restart_containers == 'true' || inputs.restart_containers == true }}
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          {
            printf '%s\n' 'set -e'
            printf '%s\n' 'cd /home/ec2-user/portfolio'
            printf '%s\n' 'aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 778230822028.dkr.ecr.us-west-2.amazonaws.com >/dev/null 2>&1 || true'
            printf '%s\n' 'export AWS_ACCOUNT_ID=778230822028'
            printf '%s\n' 'COMPOSE_FILE="deploy/compose/docker-compose.yml"'
            # Avoid full down to reduce downtime; rely on up --force-recreate per profile
            printf '%s\n' '# docker-compose down || true'
            printf '%s\n' ''
            printf '%s\n' 'case "${ENVIRONMENT}" in'
            printf '%s\n' '  prod)'
            printf '%s\n' '    COMPOSE_PROFILES=prod docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    COMPOSE_PROFILES=prod docker-compose -f "$COMPOSE_FILE" up -d --force-recreate'
            printf '%s\n' '    ;;'
            printf '%s\n' '  dev)'
            printf '%s\n' '    COMPOSE_PROFILES=dev docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    COMPOSE_PROFILES=dev docker-compose -f "$COMPOSE_FILE" up -d --force-recreate'
            printf '%s\n' '    ;;'
            printf '%s\n' '  both)'
            printf '%s\n' '    COMPOSE_PROFILES=prod docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    COMPOSE_PROFILES=prod docker-compose -f "$COMPOSE_FILE" up -d || true'
            printf '%s\n' '    COMPOSE_PROFILES=dev docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    COMPOSE_PROFILES=dev docker-compose -f "$COMPOSE_FILE" up -d || true'
            printf '%s\n' '    ;;'
            printf '%s\n' 'esac'
          } | ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" "ENVIRONMENT='${ENVIRONMENT}' bash -s"

      - name: Health checks
        if: always()
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          check() { ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" "curl -s -o /dev/null -w '%{http_code}' http://localhost:$1$2"; }
          if [ "$ENVIRONMENT" = "prod" ] || [ "$ENVIRONMENT" = "both" ]; then
            test "$(check 3000 /)" = "200" || echo "WARN: frontend prod not 200" >&2
            test "$(check 3001 /api/health)" = "200" || echo "WARN: backend prod health not 200" >&2
          fi
          if [ "$ENVIRONMENT" = "dev" ] || [ "$ENVIRONMENT" = "both" ]; then
            test "$(check 4000 /)" = "200" || echo "WARN: frontend dev not 200" >&2
            test "$(check 4001 /api/health)" = "200" || echo "WARN: backend dev health not 200" >&2
          fi
