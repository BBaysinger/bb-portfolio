# Redeploy Workflow
# GitHub Actions workflow for container restarts with runtime environment file generation
# -----------------------------------------------------------------------------------------
# Regenerates .env files on EC2 from GitHub Secrets and restarts Docker Compose services.
# This is the primary mechanism for injecting secrets into containers without storing them
# in git or passing them through local machines.
#
# Role in deployment architecture:
# - Called by deployment-orchestrator.sh after Terraform provisions/updates instances
# - Called by update-containers-gh.sh for container-only updates
# - Can be triggered manually for emergency restarts or env refresh
# - Invoked via workflow_call from other workflows for reusable orchestration
# - Supports both active and candidate instances via dynamic IP targeting
#
# Security model (why this workflow exists):
# - Secrets stored encrypted in GitHub (Settings → Secrets and variables → Actions)
# - This workflow has access to secrets; local machines and scripts do NOT
# - Generates .env.prod/.env.dev on EC2 by SSHing in and templating secrets
# - Containers started with these env files; secrets never committed to git
# - Alternative SSH fallback exists but requires .github-secrets.private.json5 locally
#
# Runtime architecture on EC2:
# - Nginx reverse proxy on host forwards to Docker Compose services
# - Four Node.js containers (node:22-slim) in two Docker Compose profiles:
#   • prod: bb-portfolio-frontend-prod:3000, bb-portfolio-backend-prod:3001
#   • dev: bb-portfolio-frontend-dev:4000, bb-portfolio-backend-dev:4001
# - Typical DNS routing:
#   • bbaysinger.com → prod frontend:3000 + backend:3001
#   • dev.bbaysinger.com → dev frontend:4000 + backend:4001
#
# Workflow steps:
# 1. Authenticate with AWS (assume GitHub OIDC role for ECR access)
# 2. Prepare SSH key from GitHub Secrets for EC2 access
# 3. Optional: Generate and upload .env.prod/.env.dev from GitHub Secrets
# 4. Optional: docker compose pull latest images from ECR/Docker Hub
# 5. Optional: docker compose up -d to restart specified profiles
# 6. Verify container health and capture logs for debugging
#
# Environment profiles:
# - prod: Production services using ECR images, production secrets
# - dev: Development services using Docker Hub images, dev secrets
# - both: Start/restart both profiles simultaneously
# - (staging: planned for future, would use prod-like secrets with staging prefix)
#
# Invocation methods:
# 1. Via deployment-orchestrator.sh (normal flow after Terraform apply)
# 2. Via update-containers-gh.sh (container-only updates)
# 3. Manual trigger (GitHub Actions UI) for emergency operations
# 4. Via gh CLI: gh workflow run redeploy.yml -f environment=prod -f refresh_env=true
#
# Common use cases:
# - Initial deployment: orchestrator provisions infra, calls this to start containers
# - Code updates: rebuild images, push to registry, call this to pull/restart
# - Secret rotation: trigger with refresh_env=true to regenerate .env files
# - Emergency restart: trigger manually with restart_containers=true
# - Blue-green: orchestrator deploys candidate, calls this to start containers there
#
# Related scripts:
# - deploy/scripts/deployment-orchestrator.sh: Calls this via gh workflow run
# - deploy/scripts/update-containers-gh.sh: Container-only caller
# - infra/bb-portfolio-management.sh: On-instance helper for ECR auth
#
name: Redeploy

on:
  workflow_dispatch:
    inputs:
      environment:
        description: Which profiles to (re)start
        type: choice
        required: true
        default: both
        options: [prod, dev, both]
        # TODO(staging): when ready, extend options to include 'staging' and wire staging secrets below.
      start_dev:
        description: Ensure dev containers are up in addition to prod
        type: choice
        required: true
        default: "true"
        options: ["true", "false"]
      refresh_env:
        description: Regenerate and upload .env files to EC2 (requires secrets)
        type: choice
        required: true
        default: "false"
        options: ["true", "false"]
      restart_containers:
        description: (Re)start containers on EC2 (docker compose pull/up)
        type: choice
        required: true
        default: "true"
        options: ["true", "false"]

  workflow_call:
    inputs:
      environment:
        description: Which profiles to (re)start
        type: string
        required: true
        default: both
        # TODO(staging): accept 'staging' here and treat as prod-like with staging-scoped secrets.
      start_dev:
        description: Ensure dev containers are up in addition to prod
        type: string
        required: true
        default: "true"
      refresh_env:
        description: Regenerate and upload .env files to EC2 (requires secrets)
        type: string
        required: true
        default: "false"
      restart_containers:
        description: (Re)start containers on EC2 (docker compose pull/up)
        type: string
        required: true
        default: "true"

jobs:
  deploy:
    name: SSH redeploy on EC2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Prevent overlapping prod/dev redeploys from stepping on each other.
    # Use per-environment concurrency so prod and dev can proceed independently.
    # If environment == 'both', fall back to a single global group.
    concurrency:
      group: redeploy-${{ inputs.environment == 'both' && 'global' || inputs.environment }}
      cancel-in-progress: true
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare SSH key
        id: ssh
        env:
          SSH_KEY_PEM: ${{ secrets.EC2_SSH_KEY_PEM }}
          SSH_KEY_ALT: ${{ secrets.EC2_SSH_KEY }}
        run: |
          set -euo pipefail
          CONTENT="${SSH_KEY_PEM:-}"
          if [ -z "$CONTENT" ] && [ -n "${SSH_KEY_ALT:-}" ]; then
            CONTENT="$SSH_KEY_ALT"
          fi
          if [ -z "$CONTENT" ]; then
            echo "Missing SSH key secret: provide EC2_SSH_KEY_PEM or EC2_SSH_KEY" >&2
            exit 1
          fi
          umask 177
          printf "%s" "$CONTENT" > key.pem
          echo "key=key.pem" >> "$GITHUB_OUTPUT"

      - name: Validate required inputs and secrets
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          REFRESH_ENV: ${{ inputs.refresh_env }}
          PROD_MONGODB_URI: ${{ secrets.PROD_MONGODB_URI }}
          PROD_PAYLOAD_SECRET: ${{ secrets.PROD_PAYLOAD_SECRET }}
          PROD_S3_BUCKET: ${{ secrets.PROD_S3_BUCKET }}
          PROD_AWS_REGION: ${{ secrets.PROD_AWS_REGION }}
          DEV_MONGODB_URI: ${{ secrets.DEV_MONGODB_URI }}
          DEV_PAYLOAD_SECRET: ${{ secrets.DEV_PAYLOAD_SECRET }}
          DEV_S3_BUCKET: ${{ secrets.DEV_S3_BUCKET }}
          DEV_AWS_REGION: ${{ secrets.DEV_AWS_REGION }}
        run: |
          set -euo pipefail
          : "${ENVIRONMENT}"
          : "${EC2_HOST}"
          : "${REFRESH_ENV}"
          # Only enforce env-specific secrets for the selected environment(s)
          if [ "$REFRESH_ENV" = "true" ]; then
            case "$ENVIRONMENT" in
              prod)
                : "${PROD_MONGODB_URI}"
                : "${PROD_PAYLOAD_SECRET}"
                : "${PROD_S3_BUCKET}"
                : "${PROD_AWS_REGION}"
                ;;
              dev)
                : "${DEV_MONGODB_URI}"
                : "${DEV_PAYLOAD_SECRET}"
                : "${DEV_S3_BUCKET}"
                : "${DEV_AWS_REGION}"
                ;;
              both)
                : "${PROD_MONGODB_URI}"
                : "${PROD_PAYLOAD_SECRET}"
                : "${PROD_S3_BUCKET}"
                : "${PROD_AWS_REGION}"
                : "${DEV_MONGODB_URI}"
                : "${DEV_PAYLOAD_SECRET}"
                : "${DEV_S3_BUCKET}"
                : "${DEV_AWS_REGION}"
                ;;
            esac
          fi

      - name: Generate env files (in runner temp)
        id: genenv
        if: ${{ inputs.refresh_env == 'true' || inputs.refresh_env == true }}
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          # Common
          S3_REGION: ${{ secrets.S3_REGION }}
          PUBLIC_PROJECTS_BUCKET: ${{ secrets.PUBLIC_PROJECTS_BUCKET }}
          NDA_PROJECTS_BUCKET: ${{ secrets.NDA_PROJECTS_BUCKET }}
          SECURITY_TXT_EXPIRES: ${{ secrets.SECURITY_TXT_EXPIRES }}
          # Unified env-guard definition lists (per-profile)
          PROD_REQUIRED_ENVIRONMENT_VARIABLES: ${{ secrets.PROD_REQUIRED_ENVIRONMENT_VARIABLES }}
          DEV_REQUIRED_ENVIRONMENT_VARIABLES: ${{ secrets.DEV_REQUIRED_ENVIRONMENT_VARIABLES }}
          # Prod
          PROD_MONGODB_URI: ${{ secrets.PROD_MONGODB_URI }}
          PROD_PAYLOAD_SECRET: ${{ secrets.PROD_PAYLOAD_SECRET }}
          PROD_S3_BUCKET: ${{ secrets.PROD_S3_BUCKET }}
          PROD_AWS_REGION: ${{ secrets.PROD_AWS_REGION }}
          PROD_FRONTEND_URL: ${{ secrets.PROD_FRONTEND_URL }}
          PROD_BACKEND_INTERNAL_URL: ${{ secrets.PROD_BACKEND_INTERNAL_URL }}
          PROD_SES_FROM_EMAIL: ${{ secrets.PROD_SES_FROM_EMAIL }}
          PROD_SES_TO_EMAIL: ${{ secrets.PROD_SES_TO_EMAIL }}
          # Dev
          DEV_MONGODB_URI: ${{ secrets.DEV_MONGODB_URI }}
          DEV_PAYLOAD_SECRET: ${{ secrets.DEV_PAYLOAD_SECRET }}
          DEV_S3_BUCKET: ${{ secrets.DEV_S3_BUCKET }}
          DEV_AWS_REGION: ${{ secrets.DEV_AWS_REGION }}
          DEV_FRONTEND_URL: ${{ secrets.DEV_FRONTEND_URL }}
          DEV_BACKEND_INTERNAL_URL: ${{ secrets.DEV_BACKEND_INTERNAL_URL }}
          DEV_SES_FROM_EMAIL: ${{ secrets.DEV_SES_FROM_EMAIL }}
          DEV_SES_TO_EMAIL: ${{ secrets.DEV_SES_TO_EMAIL }}
        run: |
          set -euo pipefail
          OUT_DIR="$(mktemp -d)"

          s_val() { [ -n "${!1:-}" ] && echo "${!1}" || echo "${2:-}"; }

          # Write files using printf to avoid heredoc/YAML indentation pitfalls
          printf "%s\n" \
            "NODE_ENV=production" \
            "ENV_PROFILE=prod" \
            "" \
            "# Env-guard definition list for prod profile" \
            "PROD_REQUIRED_ENVIRONMENT_VARIABLES=$(s_val PROD_REQUIRED_ENVIRONMENT_VARIABLES)" \
            "" \
            "PROD_AWS_REGION=$(s_val PROD_AWS_REGION \"$S3_REGION\")" \
            "" \
            "PROD_MONGODB_URI=$(s_val PROD_MONGODB_URI)" \
            "PROD_PAYLOAD_SECRET=$(s_val PROD_PAYLOAD_SECRET)" \
            "" \
            "PROD_S3_BUCKET=$(s_val PROD_S3_BUCKET)" \
            "PUBLIC_PROJECTS_BUCKET=$(s_val PUBLIC_PROJECTS_BUCKET)" \
            "NDA_PROJECTS_BUCKET=$(s_val NDA_PROJECTS_BUCKET)" \
            "S3_REGION=$(s_val S3_REGION \"$PROD_AWS_REGION\")" \
            "" \
            "PROD_FRONTEND_URL=$(s_val PROD_FRONTEND_URL)" \
            "PROD_BACKEND_INTERNAL_URL=$(s_val PROD_BACKEND_INTERNAL_URL 'http://bb-portfolio-backend-prod:3000')" \
            "" \
            "SECURITY_TXT_EXPIRES=$(s_val SECURITY_TXT_EXPIRES)" \
            "" \
            "PROD_SES_FROM_EMAIL=$(s_val PROD_SES_FROM_EMAIL)" \
            "PROD_SES_TO_EMAIL=$(s_val PROD_SES_TO_EMAIL)" \
            > "$OUT_DIR/backend.env.prod"

          printf "%s\n" \
            "NODE_ENV=development" \
            "ENV_PROFILE=dev" \
            "PORT=3000" \
            "" \
            "# Env-guard definition list for dev profile" \
            "DEV_REQUIRED_ENVIRONMENT_VARIABLES=$(s_val DEV_REQUIRED_ENVIRONMENT_VARIABLES)" \
            "" \
            "DEV_AWS_REGION=$(s_val DEV_AWS_REGION \"$S3_REGION\")" \
            "" \
            "DEV_MONGODB_URI=$(s_val DEV_MONGODB_URI)" \
            "DEV_PAYLOAD_SECRET=$(s_val DEV_PAYLOAD_SECRET)" \
            "" \
            "DEV_S3_BUCKET=$(s_val DEV_S3_BUCKET)" \
            "PUBLIC_PROJECTS_BUCKET=$(s_val PUBLIC_PROJECTS_BUCKET)" \
            "NDA_PROJECTS_BUCKET=$(s_val NDA_PROJECTS_BUCKET)" \
            "S3_REGION=$(s_val S3_REGION \"$DEV_AWS_REGION\")" \
            "" \
            "DEV_FRONTEND_URL=$(s_val DEV_FRONTEND_URL)" \
            "DEV_BACKEND_INTERNAL_URL=$(s_val DEV_BACKEND_INTERNAL_URL 'http://bb-portfolio-backend-dev:3000')" \
            "" \
            "SECURITY_TXT_EXPIRES=$(s_val SECURITY_TXT_EXPIRES)" \
            "" \
            "DEV_SES_FROM_EMAIL=$(s_val DEV_SES_FROM_EMAIL)" \
            "DEV_SES_TO_EMAIL=$(s_val DEV_SES_TO_EMAIL)" \
            > "$OUT_DIR/backend.env.dev"

          printf "%s\n" \
            "NODE_ENV=production" \
            "ENV_PROFILE=prod" \
            "" \
            "PROD_BACKEND_INTERNAL_URL=$(s_val PROD_BACKEND_INTERNAL_URL 'http://bb-portfolio-backend-prod:3000')" \
            "" \
            "PUBLIC_PROJECTS_BUCKET=$(s_val PUBLIC_PROJECTS_BUCKET)" \
            "NDA_PROJECTS_BUCKET=$(s_val NDA_PROJECTS_BUCKET)" \
            > "$OUT_DIR/frontend.env.prod"

          printf "%s\n" \
            "NODE_ENV=development" \
            "ENV_PROFILE=dev" \
            "" \
            "DEV_BACKEND_INTERNAL_URL=$(s_val DEV_BACKEND_INTERNAL_URL 'http://bb-portfolio-backend-dev:3000')" \
            "" \
            "PUBLIC_PROJECTS_BUCKET=$(s_val PUBLIC_PROJECTS_BUCKET)" \
            "NDA_PROJECTS_BUCKET=$(s_val NDA_PROJECTS_BUCKET)" \
            > "$OUT_DIR/frontend.env.dev"

          echo "dir=$OUT_DIR" >> "$GITHUB_OUTPUT"

      - name: Upload env files to EC2
        if: ${{ inputs.refresh_env == 'true' || inputs.refresh_env == true }}
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          SSH_OPTS: -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=10 -o ServerAliveInterval=5 -o ServerAliveCountMax=2 -o PreferredAuthentications=publickey -o PubkeyAuthentication=yes -o TCPKeepAlive=yes -o Compression=yes
        run: |
          set -euo pipefail
          OUT_DIR='${{ steps.genenv.outputs.dir }}'
          test -n "$OUT_DIR" && test -d "$OUT_DIR"
          echo "== Packaging env files for single transfer =="
          tar -C "$OUT_DIR" -czf env-bundle.tgz backend.env.prod backend.env.dev frontend.env.prod frontend.env.dev
          echo "Bundle size:" $(du -h env-bundle.tgz | cut -f1)
          # Prepare remote directories and ensure correct ownership (idempotent)
          ssh -i "${{ steps.ssh.outputs.key }}" $SSH_OPTS ec2-user@"$EC2_HOST" "sudo mkdir -p /home/ec2-user/bb-portfolio/{backend,frontend} && sudo chown -R ec2-user:ec2-user /home/ec2-user/bb-portfolio"
          # Single compressed upload with retry (handles transient kex resets)
          upload_attempts=0
          until scp -i "${{ steps.ssh.outputs.key }}" $SSH_OPTS env-bundle.tgz ec2-user@"$EC2_HOST":/home/ec2-user/bb-portfolio/env-bundle.tgz; do
            upload_attempts=$((upload_attempts+1))
            if [ $upload_attempts -ge 3 ]; then
              echo "Env bundle upload failed after $upload_attempts attempts" >&2
              exit 1
            fi
            echo "Upload attempt $upload_attempts failed; retrying in 4s..." >&2
            sleep 4
          done
          # Remote extract atomically then cleanup temp
          ssh -i "${{ steps.ssh.outputs.key }}" $SSH_OPTS ec2-user@"$EC2_HOST" $'set -e
            cd /home/ec2-user/bb-portfolio
            tar -xzf env-bundle.tgz || { echo "Failed to extract env bundle" >&2; exit 1; }
            mv -f backend.env.prod backend/.env.prod
            mv -f backend.env.dev backend/.env.dev
            mv -f frontend.env.prod frontend/.env.prod
            mv -f frontend.env.dev frontend/.env.dev
            rm -f env-bundle.tgz
            echo "Env files deployed:"; ls -l backend/.env.* frontend/.env.*
          '
          echo "== Env upload complete =="

      - name: Upload compose file to EC2
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          # Ensure target directory exists on EC2
          ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=30 ec2-user@"$EC2_HOST" "sudo mkdir -p /home/ec2-user/bb-portfolio/deploy/compose && sudo chown -R ec2-user:ec2-user /home/ec2-user/bb-portfolio"
          # Upload the compose file from repo to the expected remote path with timeout and compression
          scp -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=30 -o ServerAliveInterval=10 -o ServerAliveCountMax=3 -C \
            "deploy/compose/docker-compose.yml" \
            ec2-user@"$EC2_HOST":/home/ec2-user/bb-portfolio/deploy/compose/docker-compose.yml

      - name: (Re)start containers
        if: ${{ inputs.restart_containers == 'true' || inputs.restart_containers == true }}
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          # Pre-clean on EC2 to prevent disk-full and name conflicts
          {
            # Do not use -u here because ENVIRONMENT may be undefined if not exported; we pass it via SSH env instead
            printf '%s\n' 'set -e'
            printf '%s\n' 'echo "== Disk usage before =="'
            printf '%s\n' 'df -h / || true'
            printf '%s\n' 'docker system df || true'
            printf '%s\n' 'echo "== Stop/remove stale containers for selected environment (ignore errors) =="'
            printf '%s\n' 'case "${ENVIRONMENT}" in'
            printf '%s\n' '  prod) docker rm -f bb-portfolio-backend-prod bb-portfolio-frontend-prod 2>/dev/null || true ;;'
            printf '%s\n' '  dev)  docker rm -f bb-portfolio-backend-dev  bb-portfolio-frontend-dev  2>/dev/null || true ;;'
            printf '%s\n' '  both) docker rm -f bb-portfolio-backend-dev  bb-portfolio-frontend-dev  bb-portfolio-backend-prod bb-portfolio-frontend-prod 2>/dev/null || true ;;'
            printf '%s\n' 'esac'
            printf '%s\n' 'echo "== Prune unused images/containers/networks (no volumes) =="'
            printf '%s\n' 'docker system prune -af || true'
            printf '%s\n' 'echo "== Prune builder cache =="'
            printf '%s\n' 'docker builder prune -af || true'
            printf '%s\n' 'echo "== Check free space and prune volumes only if critically low =="'
            # Use POSIX df -Pk, sed + cut to avoid any $ expansion in shells
            printf '%s\n' "FREE_KB=\$(df -Pk / | sed -n '2p' | tr -s ' ' | cut -d' ' -f4)"
            printf '%s\n' 'THRESHOLD_KB=$((3 * 1024 * 1024)) # 3GB'
            printf '%s\n' 'if [ "$FREE_KB" -lt "$THRESHOLD_KB" ]; then'
            printf '%s\n' "  echo \"Low disk space detected (\$(df -h / | sed -n '2p' | tr -s ' ' | cut -d' ' -f4)) — pruning unused volumes...\""
            printf '%s\n' '  docker volume prune -f || true'
            printf '%s\n' 'fi'
            printf '%s\n' 'echo "== Disk usage after prune =="'
            printf '%s\n' 'df -h / || true'
            printf '%s\n' 'docker system df || true'
          } | ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" "ENVIRONMENT='${ENVIRONMENT}' bash -s"

      - name: Sync Nginx config and reload
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          ENVIRONMENT: ${{ inputs.environment }}
        run: |
          set -euo pipefail
          echo "== Uploading Nginx vhost config =="
          scp -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -C \
            deploy/nginx/bb-portfolio.conf ec2-user@"$EC2_HOST":/home/ec2-user/bb-portfolio/bb-portfolio.conf
          echo "== Installing to /etc/nginx/conf.d and reloading =="
          ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" $'set -e
            sudo mkdir -p /etc/nginx/conf.d
            sudo mv -f /home/ec2-user/bb-portfolio/bb-portfolio.conf /etc/nginx/conf.d/bb-portfolio.conf
            sudo chown root:root /etc/nginx/conf.d/bb-portfolio.conf
            # Auto-append SSL blocks if missing and certs exist (idempotent)
            if ! grep -q "listen 443" /etc/nginx/conf.d/bb-portfolio.conf && [ -d /etc/letsencrypt/live/bbaysinger.com ]; then
              echo "Appending SSL blocks to nginx config (auto)";
              sudo tee -a /etc/nginx/conf.d/bb-portfolio.conf >/dev/null <<'CONF'
server {
  listen 443 ssl;
  server_name bbaysinger.com www.bbaysinger.com;
  ssl_certificate     /etc/letsencrypt/live/bbaysinger.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/bbaysinger.com/privkey.pem;
  include /etc/letsencrypt/options-ssl-nginx.conf;
  location = /healthz { return 200 'ok'; add_header Content-Type text/plain; }
  location /api/ { proxy_pass http://127.0.0.1:3001/; }
  location / { proxy_pass http://127.0.0.1:3000/; }
}
server {
  listen 443 ssl;
  server_name dev.bbaysinger.com;
  ssl_certificate     /etc/letsencrypt/live/bbaysinger.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/bbaysinger.com/privkey.pem;
  include /etc/letsencrypt/options-ssl-nginx.conf;
  location = /healthz { return 200 'ok'; add_header Content-Type text/plain; }
  location /api/ { proxy_pass http://127.0.0.1:4001/; }
  location / { proxy_pass http://127.0.0.1:4000/; }
}
CONF
            fi
            sudo nginx -t
            sudo systemctl reload nginx
            echo "Nginx active: $(systemctl is-active nginx)"
            echo "Listeners:"; sudo ss -ltnp | egrep ":80|:443" || true
            echo "HTTP /healthz:"; curl -s -I --max-time 4 http://127.0.0.1/healthz || true
          '

          # Now perform the actual restart using docker-compose
          {
            printf '%s\n' 'set -e'
            printf '%s\n' 'cd /home/ec2-user/bb-portfolio'
            printf '%s\n' 'aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 778230822028.dkr.ecr.us-west-2.amazonaws.com >/dev/null 2>&1 || true'
            printf '%s\n' 'export AWS_ACCOUNT_ID=778230822028'
            printf '%s\n' 'COMPOSE_FILE="deploy/compose/docker-compose.yml"'
            # Avoid full down to reduce downtime; rely on up --force-recreate per profile
            printf '%s\n' '# docker-compose -f "$COMPOSE_FILE" down --remove-orphans || true'
            printf '%s\n' ''
            # Retry helper to tolerate transient "removal in progress" errors from Docker
            printf '%s\n' 'try_up() {'
            printf '%s\n' '  local profile="$1"'
            printf '%s\n' '  local attempts=0'
            printf '%s\n' '  until [ $attempts -ge 3 ]; do'
            printf '%s\n' '    if COMPOSE_PROFILES="$profile" docker-compose -f "$COMPOSE_FILE" up -d --force-recreate; then'
            printf '%s\n' '      return 0'
            printf '%s\n' '    fi'
            printf '%s\n' '    attempts=$((attempts+1))'
            printf '%s\n' '    echo "compose up failed for $profile (attempt $attempts), retrying in 5s..."'
            printf '%s\n' '    sleep 5'
            printf '%s\n' '  done'
            printf '%s\n' '  echo "compose up failed for $profile after retries" >&2'
            printf '%s\n' '  return 1'
            printf '%s\n' '}'
            printf '%s\n' 'case "${ENVIRONMENT}" in'
            printf '%s\n' '  prod)'
            printf '%s\n' 'ENVIRONMENT="${ENVIRONMENT:-both}"'
            printf '%s\n' '    COMPOSE_PROFILES=prod docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    try_up prod'
            printf '%s\n' '    ;;'
            printf '%s\n' '  dev)'
            printf '%s\n' '    COMPOSE_PROFILES=dev docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    try_up dev'
            printf '%s\n' '    ;;'
            printf '%s\n' '  both)'
            printf '%s\n' '    COMPOSE_PROFILES=prod docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    try_up prod || true'
            printf '%s\n' '    COMPOSE_PROFILES=dev docker-compose -f "$COMPOSE_FILE" pull || true'
            printf '%s\n' '    try_up dev || true'
            printf '%s\n' '    ;;'
            printf '%s\n' 'esac'
          } | ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" "ENVIRONMENT='${ENVIRONMENT}' bash -s"

      - name: Diagnose services (containers and nginx)
        if: failure()
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          ssh -i "${{ steps.ssh.outputs.key }}" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" $'set -e
            echo "== Docker ps =="
            docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}"
            echo
            echo "== Docker compose version =="
            if docker compose version >/dev/null 2>&1; then
              COMPOSE_BIN="docker compose"
            else
              COMPOSE_BIN="docker-compose"
            fi
            $COMPOSE_BIN version || true
            echo
            echo "== Listening ports (ss) =="
            ss -lntp || true
            echo
            echo "== Compose ps (prod) =="
            COMPOSE_PROFILES=prod $COMPOSE_BIN -f /home/ec2-user/bb-portfolio/deploy/compose/docker-compose.yml ps || true
            echo
            echo "== Nginx status =="
            systemctl is-active nginx || true
            # nginx -t will often fail for non-root due to cert perms; tolerate but still show output
            nginx -t || true
            echo
            echo "== HTTP probes =="
            for url in \
              "http://localhost:3000/" \
              "http://localhost:3001/api/health" \
              "http://localhost:4000/" \
              "http://localhost:4001/api/health"; do
              code=$(curl -s -o /dev/null -w "%{http_code}" "$url" || true)
              echo "$code $url"
            done
          '

      - name: Health checks
        if: always()
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          START_DEV: ${{ inputs.start_dev }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          HEALTH_ATTEMPTS: 4
          HEALTH_DELAY_SECONDS: 3
          CURL_ATTEMPTS: 3
          CURL_DELAY_SECONDS: 2
          CURL_MAX_TIME_SECONDS: 3
          CURL_CONNECT_TIMEOUT: 1
        run: |
          set -euo pipefail
          KEY="${{ steps.ssh.outputs.key }}"
          ATTEMPTS="${HEALTH_ATTEMPTS}"; DELAY="${HEALTH_DELAY_SECONDS}"
          CURL_ATTEMPTS="${CURL_ATTEMPTS}"; CURL_DELAY="${CURL_DELAY_SECONDS}"
          CURL_MAX_TIME="${CURL_MAX_TIME_SECONDS}"; CURL_CONNECT_TIMEOUT_SEC="${CURL_CONNECT_TIMEOUT}"
          ssh_cmd() { ssh -i "$KEY" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" "$@"; }
          poll_containers() {
            local env="$1"; local tries=0
            local be_name fe_name
            case "$env" in
              prod) be_name="bb-portfolio-backend-prod"; fe_name="bb-portfolio-frontend-prod";;
              dev)  be_name="bb-portfolio-backend-dev";  fe_name="bb-portfolio-frontend-dev";;
            esac
            echo "Polling container health for $env (max $ATTEMPTS attempts, $DELAY s delay)" >&2
            while [ $tries -lt $ATTEMPTS ]; do
              # Status lines: backend has (healthy|health: starting), frontend usually just Up ...
              local be_status fe_status
              be_status=$(ssh_cmd "docker ps --filter name=$be_name --format '{{.Status}}'" || true)
              fe_status=$(ssh_cmd "docker ps --filter name=$fe_name --format '{{.Status}}'" || true)
              # Ready conditions
              be_ready=false; fe_ready=false
              if echo "$be_status" | grep -qi 'healthy'; then be_ready=true; fi
              # frontends often have no health check – treat any Up as ready
              if echo "$fe_status" | grep -qi '^Up '; then fe_ready=true; fi
              if [[ "$be_ready" == true && "$fe_ready" == true ]]; then
                echo "Containers ready for $env (backend: $be_status, frontend: $fe_status)" >&2
                return 0
              fi
              tries=$((tries+1))
              echo "Attempt $tries/$ATTEMPTS ($env) not ready yet (be='$be_status' fe='$fe_status')" >&2
              sleep "$DELAY"
            done
            echo "WARN: Containers not healthy after $ATTEMPTS attempts ($env) (be='$be_status' fe='$fe_status')" >&2
            return 1
          }
          curl_with_retry() {
            local port="$1"; local path="$2"; local label="$3"; local attempt=0; local code=""
            while [ $attempt -lt "$CURL_ATTEMPTS" ]; do
              code=$(ssh_cmd "curl --max-time ${CURL_MAX_TIME} --connect-timeout ${CURL_CONNECT_TIMEOUT_SEC} -s -o /dev/null -w '%{http_code}' http://localhost:${port}${path} -L" || echo '000')
              # Success on 2xx/3xx; treat 000 as transient unless final attempt
              if [[ "$code" == 2* || "$code" == 3* ]]; then
                echo "OK $label HTTP $code" >&2; return 0
              fi
              attempt=$((attempt+1))
              if [[ "$code" == "000" && $attempt -lt "$CURL_ATTEMPTS" ]]; then
                echo "Transient $label code 000 (attempt $attempt/$CURL_ATTEMPTS)" >&2; sleep "$CURL_DELAY"; continue
              fi
              echo "Attempt $attempt/$CURL_ATTEMPTS $label code=$code" >&2
              sleep "$CURL_DELAY"
            done
            echo "WARN: $label unhealthy after $CURL_ATTEMPTS attempts (last code=$code)" >&2
            return 1
          }
          # Environments to check
          if [ "$ENVIRONMENT" = "prod" ] || [ "$ENVIRONMENT" = "both" ]; then poll_containers prod || true; fi
          # Always check dev when environment=dev. When environment=both, honor START_DEV to optionally include dev.
          if [ "$ENVIRONMENT" = "dev" ]; then
            poll_containers dev || true
          elif [ "$ENVIRONMENT" = "both" ] && { [ "${START_DEV}" = "true" ] || [ "${START_DEV}" = true ]; }; then
            poll_containers dev || true
          fi
          if [ "$ENVIRONMENT" = "prod" ] || [ "$ENVIRONMENT" = "both" ]; then
            curl_with_retry 3000 / "frontend prod"
            curl_with_retry 3001 /api/health "backend prod health"
          fi
          if [ "$ENVIRONMENT" = "dev" ]; then
            curl_with_retry 4000 / "frontend dev"
            curl_with_retry 4001 /api/health "backend dev health"
          elif [ "$ENVIRONMENT" = "both" ] && { [ "${START_DEV}" = "true" ] || [ "${START_DEV}" = true ]; }; then
            curl_with_retry 4000 / "frontend dev"
            curl_with_retry 4001 /api/health "backend dev health"
          fi

      - name: Dump container logs on failure
        if: failure()
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          set -euo pipefail
          KEY="${{ steps.ssh.outputs.key }}"
          dump_logs() {
            local name="$1"
            echo "==== logs: $name (last 200 lines) ===="
            ssh -i "$KEY" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ec2-user@"$EC2_HOST" \
              "docker logs --tail 200 --timestamps $name 2>&1 || true"
            echo
          }
          case "$ENVIRONMENT" in
            prod)
              dump_logs bb-portfolio-frontend-prod
              dump_logs bb-portfolio-backend-prod
              ;;
            dev)
              dump_logs bb-portfolio-frontend-dev
              dump_logs bb-portfolio-backend-dev
              ;;
            both)
              dump_logs bb-portfolio-frontend-prod
              dump_logs bb-portfolio-backend-prod
              dump_logs bb-portfolio-frontend-dev
              dump_logs bb-portfolio-backend-dev
              ;;
          esac
