{
  // =====================
  // Root package.json5 for monorepo tooling only
  // =====================
  // ğŸ“Œ NOTE: This root package.json is ONLY for managing monorepo-level tooling and scripts.
  // It does not represent a real app or library (and should not be published to npm).
  // Root package name for the portfolio monorepo
  // Monorepo root name (not a real app or package)
  "name": "bb-portfolio-monorepo-root",
  // Prevents accidental publishing to npm registry
  // Prevent publishing to npm registry
  "private": true,
  // Optional: Enable npm workspaces by uncommenting the line below
  // "workspaces": ["frontend", "backend"],
  "scripts": {
    // Shortcut to start backend and frontend locally (bare metal, no Docker)
    "dev": "npm run bareMetalDev:all",
    // Start only the backend locally (bare metal)
    "dev:backend": "npm run bareMetalDev:backend",
    // Start only the frontend locally (bare metal)
    "dev:frontend": "npm run bareMetalDev:frontend",
    // ğŸš€ Experimental build using Turbopack for faster frontend builds
    "turbopack": "cd frontend && NEXT_TELEMETRY_DISABLED=1 npx next build --turbopack",
    // =============================================================================
    // ğŸš€ DEVELOPMENT MODES OVERVIEW (for junior developers)
    // =============================================================================
    // 1. ğŸ–¥ï¸  Bare Metal: Run directly on your machine (fastest, most direct)
    // 2. ğŸ³ Docker SSR: Containerized with hot reload (pages render on-demand)
    // 3. ğŸ—ï¸  Docker SSG: Pre-builds pages like production (slower, but tests real build)
    // 4. ğŸŒ Caddy Proxy: Same as SSR but with production-like URLs (single port)
    // ğŸ‘‡ Pick the workflow that matches the validation you need so you don't mix modes.
    // Choose based on what you're testing:
    // - Daily dev: Use Bare Metal or Docker SSR
    // - Pre-commit: Use Docker SSG to test production builds
    // - URL testing: Use Caddy for production-like routing
    // =============================================================================
    // ğŸ–¥ï¸ Build both backend and frontend locally without Docker (bare metal, laptop dev)
    "build:all": "npm run format && concurrently \"npm run build:backend\" \"npm run build:frontend\" --names \"backend,frontend\" --prefix-colors \"blue,green\"",
    // ğŸ–¥ï¸ Build backend service locally (bare metal, laptop dev)
    "build:backend": "cd backend && npm run build",
    // ğŸ–¥ï¸ Build frontend service locally (bare metal, laptop dev)
    "build:frontend": "cd frontend && npm run build",
    // ğŸ§° Force a plain Webpack build to reproduce issues that only happen outside Turbopack.
    "build:frontend:webpack": "cd frontend && npm run build:webpack",
    // =============================================================================
    // ğŸ³ DOCKER DEVELOPMENT (Containerized - consistent across machines)
    // =============================================================================
    // ğŸ³ Build both frontend and backend Docker images using docker-compose local profile
    // Uses the local profile which includes development-optimized builds with hot reload
    "docker:build": "docker compose -f deploy/compose/docker-compose.yml --profile local build",
    // âš¡ DEVELOPMENT MODE (SSR): Start containers with hot reload for fast development
    // Frontend: http://localhost:8080, Backend: http://localhost:8081
    // Uses 'npm run dev' with volume mounts - pages render on-demand with fresh data from backend
    "docker:up": "docker compose -f deploy/compose/docker-compose.yml --profile local up --build",
    // â–¶ï¸ Same as docker:up but runs in background (doesn't block your terminal)
    // Use this if you want to continue using your terminal while containers run
    "docker:up:detached": "docker compose -f deploy/compose/docker-compose.yml --profile local up --build -d",
    // âš¡ Same as docker:up but with React Strict Mode disabled (helps with legacy libraries)
    // Useful when React's strict mode causes issues with third-party components
    "docker:up:no-strict": "REACT_STRICT_MODE=false docker compose -f deploy/compose/docker-compose.yml --profile local up --build",
    // â–¶ï¸ Same as docker:up:no-strict but runs in background (detached mode)
    "docker:up:no-strict:detached": "REACT_STRICT_MODE=false docker compose -f deploy/compose/docker-compose.yml --profile local up --build -d",
    // ğŸ›‘ Stop and remove all local development containers
    // Cleans up containers, networks, and anonymous volumes created by docker:up
    "docker:down": "docker compose -f deploy/compose/docker-compose.yml --profile local down",
    // ğŸ“‹ Follow logs from both frontend and backend containers in real-time
    // Useful when running in detached mode to see what's happening
    "docker:logs": "docker compose -f deploy/compose/docker-compose.yml --profile local logs -f",
    // ğŸ—ï¸ BUILD MODE: Build static site generation containers (local-ssg profile)
    "docker:ssg:build": "docker compose -f deploy/compose/docker-compose.yml --profile local-ssg build",
    // ğŸ—ï¸ PRODUCTION MODE (SSG): Pre-builds all pages with data baked-in at build time
    // Frontend: Static HTML files generated, Backend: Hot reload for development
    // Slower startup but faster page loads - tests how production will behave
    "docker:ssg:up": "docker compose -f deploy/compose/docker-compose.yml --profile local-ssg up --build",
    // ğŸ—ï¸ Same as docker:ssg:up but runs in background (detached mode)
    "docker:ssg:up:detached": "docker compose -f deploy/compose/docker-compose.yml --profile local-ssg up --build -d",
    // ğŸ—ï¸ Same as docker:ssg:up but with React Strict Mode disabled (for compatibility)
    "docker:ssg:up:no-strict": "REACT_STRICT_MODE=false docker compose -f deploy/compose/docker-compose.yml --profile local-ssg up --build",
    // ğŸ—ï¸ Same as docker:ssg:up:no-strict but runs in background (detached mode)
    "docker:ssg:up:no-strict:detached": "REACT_STRICT_MODE=false docker compose -f deploy/compose/docker-compose.yml --profile local-ssg up --build -d",
    // ğŸ›‘ Stop and remove static site generation containers (local-ssg profile)
    "docker:ssg:down": "docker compose -f deploy/compose/docker-compose.yml --profile local-ssg down",
    // ğŸ“‹ Follow logs from static site generation containers in real-time (local-ssg profile)
    "docker:ssg:logs": "docker compose -f deploy/compose/docker-compose.yml --profile local-ssg logs -f",
    // ğŸ³ Build backend Docker image for Docker Hub (dev tag)
    // NOTE: Builds the production runtime stage with ENV_PROFILE=dev (no hot reload)
    // This ensures EC2 dev behaves like prod, just with dev config.
    "docker:build:backend": "docker build --target runtime --build-arg ENV_PROFILE=dev -t bhbaysinger/bb-portfolio-backend:dev ./backend",
    // ğŸ³ Build frontend Docker image for Docker Hub (dev tag)
    // NOTE: Builds the production runner stage with ENV_PROFILE=dev (no hot reload)
    // Dev internal URL points to the dev compose service name for server-to-server calls.
    "docker:build:frontend": "docker build --target runner --build-arg ENV_PROFILE=dev --build-arg BACKEND_INTERNAL_URL=http://bb-portfolio-backend-dev:3000 -t bhbaysinger/bb-portfolio-frontend:dev ./frontend",
    // ğŸš€ Push backend Docker image to Docker Hub (dev tag)
    "docker:push:backend": "docker push bhbaysinger/bb-portfolio-backend:dev",
    // ğŸš€ Push frontend Docker image to Docker Hub (dev tag)
    "docker:push:frontend": "docker push bhbaysinger/bb-portfolio-frontend:dev",
    // ğŸš€ Build and push both backend and frontend images to Docker Hub (dev tag).
    "docker:build-push": "bash deploy/scripts/publish-dockerhub-dev-images.sh",
    // ğŸš€ Build and push production images to AWS ECR (:latest for frontend/backend)
    // Uses scripts/publish-ecr-images.sh which reads build-time secrets from infra/terraform.tfvars
    "ecr:build-push": "bash deploy/scripts/publish-ecr-images.sh",
    // ğŸŒ PROXY MODE (SSR + URL consistency): Single port access like production
    // Access everything at http://localhost:8080 â€” this mirrors prodâ€™s â€œno explicit backend port in the URLâ€ behavior.
    // When you run with the proxy (npm run caddy:up), you get a single entrypoint at http://localhost:8080 and:
    //   â€¢ /api and /admin are proxied to the backend
    //   â€¢ everything else goes to the frontend
    // The only â€œextraâ€ is the Docker network (infrastructure), not an extra app.
    // Uses compose profiles: local (frontend+backend dev) + proxy (Caddy)
    // Hey AI: Use this command to start local development (this is the default)
    // Starts proxy + frontend using helper (warns if prune is overdue)
    "caddy:up": "zsh deploy/scripts/caddy-helper.sh up",
    // ğŸŒ Same as caddy:up but with React Strict Mode disabled (for legacy compatibility)
    // Same as caddy:up with React Strict Mode disabled
    "caddy:up:no-strict": "REACT_STRICT_MODE=false zsh deploy/scripts/caddy-helper.sh up",
    // ğŸ›‘ Stop Caddy (and its dependencies) cleanly
    // Stop only Caddy via helper (no full reset)
    "caddy:down": "zsh deploy/scripts/caddy-helper.sh down",
    // ğŸ§¹ Force-remove a stale caddy container if it was created outside the current compose project
    "caddy:down:force": "docker rm -f bb-portfolio-backend-local bb-portfolio-frontend-local bb-portfolio-caddy-local || true",
    // ğŸ“‹ Follow Caddy reverse proxy logs in real-time
    // Tail Caddy logs via helper
    "caddy:logs": "zsh deploy/scripts/caddy-helper.sh logs",
    // ğŸ”„ Restart Caddy in-place (recreate only the proxy)
    // Restart Caddy via helper
    "caddy:restart": "zsh deploy/scripts/caddy-helper.sh restart",
    // âš¡ Reload Caddy configuration without restarting containers.
    // Use this when you changed only the Caddyfile (routes/headers/upstreams). It does NOT rebuild frontend JS.
    // For fresh JS or assets, rebuild/recreate the frontend container (e.g., `docker:up` or `caddy:up`) so Next.js serves the new build.
    "caddy:reload": "docker exec bb-portfolio-caddy-local caddy reload --config /etc/caddy/Caddyfile",
    // âœ… Check only: validate Caddyfile syntax inside the running container (no changes applied).
    // Safe to run before reload. Use when editing the Caddyfile and you want to verify it parses.
    "caddy:config:validate": "COMPOSE_PROFILES=local,proxy docker compose -f deploy/compose/docker-compose.yml exec -T caddy-local caddy validate --config /etc/caddy/Caddyfile --adapter caddyfile",
    // ğŸš€ Apply the validated configuration with zero downtime via admin API.
    // Again, this only affects proxy config. It wonâ€™t refresh JS bundles.
    "caddy:config:reload": "COMPOSE_PROFILES=local,proxy docker compose -f deploy/compose/docker-compose.yml exec -T caddy-local caddy reload --config /etc/caddy/Caddyfile --adapter caddyfile",
    // ğŸ” One-shot: validate then reload Caddy if validation succeeds.
    "caddy:config:apply": "npm run caddy:config:validate && npm run caddy:config:reload",
    // â„¹ï¸ To ensure JS is fresh:
    //   - In dev SSR mode, the frontend dev server handles HMR; use `docker:up` or `caddy:up` to start it. No Caddy reload needed for code changes.
    //   - For production-like builds, rebuild the frontend image (e.g., `docker:build:frontend`) and recreate the container via `caddy:restart` or `caddy:up`.
    // ğŸ”§ Frontend container helpers (local dev):
    // Restart only the frontend dev container (use if HMR looks stuck)
    "frontend:restart": "docker restart bb-portfolio-frontend-local",
    // Purge .next inside the running frontend dev container (forces clean rebuild on next request)
    "frontend:purge": "docker exec -t bb-portfolio-frontend-local sh -lc 'rm -rf .next && echo Purged .next'",
    // Rebuild images for the SSG profile (frontend gets a fresh production-style build)
    // Note: This rebuilds the profileâ€™s images; to start them, run `docker:ssg:up` or `docker:ssg:up:detached`.
    "frontend:rebuild:ssg": "npm run docker:ssg:build",
    // ğŸ“Š Check status of portfolio containers
    "caddy:status": "docker ps --filter name=bb-portfolio- --format 'table {{.Names}}\\t{{.Status}}\\t{{.Ports}}'",
    // ğŸ§½ Run Docker cleanup + prune tasks to prevent stale containers, volumes, and caches.
    "docker:maintenance": "zsh deploy/scripts/docker-maintenance.sh",
    // â„¹ï¸ Note on routing through Caddy:
    // - If your frontend uses relative paths like fetch('/api/...'), browser requests will always hit the proxy at 8080
    //   (when using caddy:up) and be routed to the backend. This fully mirrors prod.
    // - If any client code builds absolute URLs from NEXT_PUBLIC_BACKEND_URL (e.g., http://localhost:8081),
    //   those requests will bypass the proxy and hit the backend directly. That still works, but itâ€™s not â€œvia Caddyâ€.
    // - For perfect parity, prefer relative paths in the browser, or set NEXT_PUBLIC_BACKEND_URL=http://localhost:8080
    //   when running with the proxy.
    // =============================================================================
    // ğŸ–¥ï¸  BARE METAL DEVELOPMENT (No Docker - runs directly on your machine)
    // =============================================================================
    // ğŸ Shortcut: Run both frontend and backend locally (bare metal dev)
    "bareMetalDev": "npm run bareMetalDev:all",
    // ğŸ¯ Run both frontend and backend in same terminal with colored output
    // Uses concurrently to show logs from both services with blue/green prefixes
    // Great for seeing everything at once, but logs can get mixed
    "bareMetalDev:all": "concurrently \"npm run bareMetalDev:backend\" \"npm run bareMetalDev:frontend\" --names \"backend,frontend\" --prefix-colors \"blue,green\"",
    // ğŸ“± Run frontend and backend in separate macOS Terminal tabs
    // Uses AppleScript to spawn new Terminal tabs for clean, separated logs
    // Perfect for managing services independently (macOS only)
    "bareMetalDev:tabs": "osascript -e 'tell application \"Terminal\" to do script \"cd \\\"$(pwd)/backend\\\" && npm run dev\"' && osascript -e 'tell application \"Terminal\" to do script \"cd \\\"$(pwd)/frontend\\\" && npm run dev\"'",
    // âš™ï¸ Run only the backend service locally (Payload CMS + API)
    // Connects to bb-portfolio-local MongoDB database via .env
    "bareMetalDev:backend": "cd backend && npm run dev",
    // ğŸ¨ Run only the frontend service locally (Next.js with hot reload)
    // Serves the React frontend with automatic reloading on file changes
    "bareMetalDev:frontend": "cd frontend && npm run dev",
    // ğŸ’… Format all files with Prettier
    // Ensures consistent code style across the entire monorepo
    "format": "prettier --write .",
    // ğŸ§¼ Run ESLint on the full codebase
    // Great for catching JS/TS issues or team rule violations
    "lint": "eslint .",
    // âœ… Fast pre-commit validation (format + lint + type check)
    // Run before every commit for quick validation (~5-10 seconds)
    // Auto-fixes ESLint issues when possible, continues with warnings
    "precommit": "prettier --write . && eslint . --fix && tsc --noEmit",
    // ğŸ›¡ï¸ Comprehensive pre-push validation (precommit + tests)
    // Run before pushing to ensure everything works (1-5 minutes)
    // Includes all precommit checks plus full test suite
    "prepush": "npm run precommit && npm test",
    // ğŸ”„ Syncs package.json5 with package.json values while preserving comments and formatting
    // Run this after editing package.json to push updates back into the annotated JSON5 version
    "sync:packages": "tsx scripts/sync-json5-packages.ts",
    // ğŸ§© Merge env-specific secret fragments into a single JSON5 before syncing.
    "secrets:bundle": "tsx scripts/merge-github-secrets.ts",
    // ğŸ“¦ Run bundle + sync for every environment in one go (single command).
    "sync:secrets": "npm run secrets:bundle && tsx scripts/sync-github-secrets.ts BBaysinger/bb-portfolio ./.github-secrets.private.json5",
    // ğŸ§ª Same as above but performs only a dry run.
    "sync:secrets:dry": "npm run secrets:bundle && tsx scripts/sync-github-secrets.ts BBaysinger/bb-portfolio ./.github-secrets.private.json5 --dry-run",
    // ğŸ“¦ Update dependencies to latest versions across all packages
    // Runs npm-check-updates in root, backend, and frontend simultaneously
    // Review changes before running npm run install:all
    "update:deps": "concurrently \"ncu -u\" \"cd backend && ncu -u\" \"cd frontend && ncu -u\" --names \"root,backend,frontend\" --prefix-colors \"yellow,blue,green\"",
    // ğŸ”½ Install dependencies in all packages after updating
    // Run after update:deps to install the newly updated dependencies
    // Handles root, backend, and frontend package installations simultaneously
    "install:all": "concurrently \"npm install\" \"cd backend && npm install\" \"cd frontend && npm install\" --names \"root,backend,frontend\" --prefix-colors \"yellow,blue,green\"",
    // ğŸª„ Generate the portfolio images from PSDs from *outside* of the repo. Run before seed:media.
    "media:export": "bash scripts/export-media.sh",
    // ğŸª„ Import images from ../cms-seedings into backend/media/* for local dev
    "media:seed": "tsx scripts/import-media-from-seedings.ts",
    // ğŸª„ Upload media only to the development S3 bucket
    "media:upload:dev": "tsx scripts/upload-media-to-s3.ts --env dev",
    // ğŸª„ Upload media only to the production S3 bucket
    "media:upload:prod": "tsx scripts/upload-media-to-s3.ts --env prod",
    // ğŸª„ Upload media to BOTH dev and prod buckets in one run
    "media:upload:both": "tsx scripts/upload-media-to-s3.ts --env both",
    // ğŸª„ Verify uploaded media files on S3 to ensure integrity
    "media:verify": "tsx scripts/verify-media-s3.ts",
    // ğŸ“¤ Upload local media files to S3 development environment
    "migrate:media:dev": "tsx scripts/upload-media-to-s3.ts --env dev",
    // ğŸ“¤ Upload local media files to S3 production environment
    "migrate:media:prod": "tsx scripts/upload-media-to-s3.ts --env prod",
    // ğŸ“¤ Upload local media files to both S3 environments (dev + prod)
    "migrate:media:both": "tsx scripts/upload-media-to-s3.ts --env both",
    // ğŸ”— PREVIEW: Update media URLs in development database to point to S3 (dry run)
    "migrate:media-urls:dev:dry": "cd backend && tsx scripts/migrate-media-to-s3.ts --env dev --dry-run",
    // ğŸ”— Update media URLs in development database to point to S3
    "migrate:media-urls:dev": "cd backend && tsx scripts/migrate-media-to-s3.ts --env dev",
    // ğŸ”— PREVIEW: Update media URLs in production database to point to S3 (dry run)
    "migrate:media-urls:prod:dry": "cd backend && tsx scripts/migrate-media-to-s3.ts --env prod --dry-run",
    // ğŸ”— Update media URLs in production database to point to S3
    "migrate:media-urls:prod": "cd backend && tsx scripts/migrate-media-to-s3.ts --env prod",
    // ğŸ“¦ PREVIEW: Complete media migration to development (upload + URL sync, dry run)
    "migrate:all:dev:dry": "npm run migrate:media:dev && npm run migrate:media-urls:dev:dry",
    // ğŸ“¦ Complete media migration to development environment (upload + URL sync)
    "migrate:all:dev": "npm run migrate:media:dev && npm run migrate:media-urls:dev",
    // ğŸ“¦ PREVIEW: Complete media migration to production (upload + URL sync, dry run)
    "migrate:all:prod:dry": "npm run migrate:media:prod && npm run migrate:media-urls:prod:dry",
    // ğŸ“¦ Complete media migration to production environment (upload + URL sync)
    "migrate:all:prod": "npm run migrate:media:prod && npm run migrate:media-urls:prod",
    // ğŸ“ Upload project files to public S3 bucket
    "projects:upload:public": "tsx scripts/upload-projects-to-s3.ts --env public",
    // ğŸ“ Upload project files to NDA S3 bucket (requires authentication to access)
    "projects:upload:nda": "tsx scripts/upload-projects-to-s3.ts --env nda",
    // ğŸ“ Upload project files to both public and NDA S3 buckets
    "projects:upload:both": "tsx scripts/upload-projects-to-s3.ts --env both",
    // ğŸ“ Verify uploaded project files on S3 to ensure integrity
    "projects:verify": "tsx scripts/verify-projects-s3.ts",
    // ğŸ”¤ In-place rename in Local: portfolio-local â†’ bb-portfolio-local (backup + restore, safe)
    "db:rename:local:portfolio-to-bb": "bash scripts/migrate-database.sh local local --source-db portfolio-local --target-db bb-portfolio-local",
    // ğŸ§ª Dry run only: show the plan for renaming local DB from portfolio-local â†’ bb-portfolio-local
    "db:rename:local:portfolio-to-bb:dry": "bash scripts/migrate-database.sh local local --source-db portfolio-local --target-db bb-portfolio-local --dry-run",
    // ğŸ”¤ In-place rename in Dev: portfolio-dev â†’ bb-portfolio-dev (backup + restore, safe)
    "db:rename:dev:portfolio-to-bb": "bash scripts/migrate-database.sh dev dev --source-db portfolio-dev --target-db bb-portfolio-dev",
    // ğŸ§ª Dry run only: show the plan for renaming dev DB from portfolio-dev â†’ bb-portfolio-dev
    "db:rename:dev:portfolio-to-bb:dry": "bash scripts/migrate-database.sh dev dev --source-db portfolio-dev --target-db bb-portfolio-dev --dry-run",
    // ğŸ”¤ In-place rename in Prod: portfolio-prod â†’ bb-portfolio-prod (backup + restore, safe but be cautious)
    "db:rename:prod:portfolio-to-bb": "bash scripts/migrate-database.sh prod prod --source-db portfolio-prod --target-db bb-portfolio-prod",
    // ğŸ§ª Dry run only: show the plan for renaming prod DB from portfolio-prod â†’ bb-portfolio-prod
    "db:rename:prod:portfolio-to-bb:dry": "bash scripts/migrate-database.sh prod prod --source-db portfolio-prod --target-db bb-portfolio-prod --dry-run",
    // ğŸ—‘ï¸ Local cleanup: backup then drop the legacy portfolio-local database
    "db:delete:local-portfolio:dry": "bash scripts/delete-database.sh --env local --db portfolio-local --dry-run",
    // ğŸ—‘ï¸ Local cleanup (apply): backup then drop portfolio-local
    "db:delete:local-portfolio": "bash scripts/delete-database.sh --env local --db portfolio-local",
    // ğŸ—‘ï¸ Dev cleanup: backup then drop the legacy portfolio-dev database
    "db:delete:dev-portfolio:dry": "bash scripts/delete-database.sh --env dev --db portfolio-dev --dry-run",
    // ğŸ—‘ï¸ Dev cleanup (apply): backup then drop portfolio-dev
    "db:delete:dev-portfolio": "bash scripts/delete-database.sh --env dev --db portfolio-dev",
    // ğŸ—‘ï¸ Prod cleanup: backup then drop the legacy portfolio-prod database
    "db:delete:prod-portfolio:dry": "bash scripts/delete-database.sh --env prod --db portfolio-prod --dry-run",
    // ğŸ—‘ï¸ Prod cleanup (apply): backup then drop portfolio-prod
    "db:delete:prod-portfolio": "bash scripts/delete-database.sh --env prod --db portfolio-prod",
    // â˜¢ï¸ğŸ’€ DANGER: NUCLEAR DATABASE REPLACEMENT - Completely overwrites prod and dev DB with local data
    // â˜¢ï¸ Convenience: run both localâ†’prod and localâ†’dev migrations sequentially (ensure backups exist first)
    // This is the default flow. Only use this, since I'm the only admin
    "db:migrate:local-to-both": "npm run db:migrate:local-to-prod && npm run db:migrate:local-to-dev",
    // â˜¢ï¸ğŸ’€ DANGER: NUCLEAR DATABASE REPLACEMENT - Completely overwrites production DB with local data
    "db:migrate:local-to-prod": "bash scripts/migrate-database.sh local prod",
    // ğŸ§ª Dry run only: print the exact mongodump/mongorestore plan for local â†’ prod without making changes
    "db:migrate:local-to-prod:dry": "bash scripts/migrate-database.sh local prod --dry-run",
    // â˜¢ï¸ DANGER: Overwrite production database with dev data (use with extreme caution)
    "db:migrate:dev-to-prod": "bash scripts/migrate-database.sh dev prod",
    // â˜¢ï¸ğŸ”¥ DANGER: APOCALYPTIC DB REPLACEMENT - Completely overwrites dev DB with local data
    "db:migrate:local-to-dev": "bash scripts/migrate-database.sh local dev",
    // â˜¢ï¸âš°ï¸ DANGER: ARMAGEDDON DB REPLACEMENT - Completely overwrites dev DB with production data
    "db:migrate:prod-to-dev": "bash scripts/migrate-database.sh prod dev",
    // ğŸ­ ORCHESTRATION: Lagoon Deployment Strategy (formerly Blue-Green)
    // =============================================================================
    // NAMING CONVENTION:
    //   orchestrate:xxx  = calls deployment-orchestrator.sh with flags (same script)
    //   orchestrate-xxx  = calls separate script (different script)
    // =============================================================================
    // WORKFLOW:
    //   1. Run `orchestrate` to deploy to the Lagoon candidate instance
    //   2. Test candidate at http://<candidate-ip> (shown in orchestrator output)
    //   3. Run `candidate-promote` to cut over candidate â†’ active (manual validation)
    //      OR use `orchestrate:auto-promote` to deploy + promote in one step (risky)
    // =============================================================================
    // Deploy to Lagoon candidate instance for testing before production promotion
    // Runs: terraform, docker builds, GitHub Actions deployment, nginx sync
    // Candidate instance is accessible by IP for validation (nginx config includes IP server block)
    "orchestrate": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --refresh-env",
    // Deploy to candidate AND auto-promote to production without manual validation
    // Runs full orchestration THEN internally invokes promotion logic with --auto-promote
    // âš ï¸ Use with caution: skips manual testing of candidate
    "orchestrate:auto-promote": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --auto-promote --refresh-env",
    // Rebuild+push both prod/dev images before dispatching redeploy workflows
    // Useful when backend/frontend code changed and new images must be published
    "orchestrate:rebuild-images": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --rebuild-images --refresh-env",
    // Same as above but auto-promotes after successful deploy
    "orchestrate:rebuild-images:auto-promote": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --rebuild-images --auto-promote --refresh-env",
    // Deploy using existing images (skip Docker build/push to registries)
    // Useful for config-only changes or when images are already built and pushed
    // Still provisions infrastructure and deploys containers from DockerHub/ECR
    "orchestrate:no-build": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --no-build --refresh-env",
    // Deploy using existing images AND auto-promote without manual validation
    // Combines --no-build (skip image building) with --auto-promote (automatic promotion)
    // Fast deployment option when images haven't changed
    "orchestrate:no-build:auto-promote": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --no-build --auto-promote --refresh-env",
    // Skip-infra deployment (no Terraform/host maintenance)
    // Rebuilds/pushes images (unless --no-build) then asks GH Actions to restart containers
    // Useful for application updates when infrastructure is stable
    "orchestrate:skip-infra": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --skip-infra --refresh-env",
    // Skip-infra deployment with auto-promotion
    // Updates containers on existing instances AND promotes automatically
    // Fastest deployment option for container updates only
    "orchestrate:skip-infra:auto-promote": "bash deploy/scripts/deployment-orchestrator.sh --profiles both --skip-infra --auto-promote --refresh-env",
    // Promote existing candidate to production (SEPARATE SCRIPT, no deployment)
    // Runs health checks, swaps Elastic IPs (activeâ†”candidate), updates instance Role tags
    // Prompts "Type 'yes' to confirm" before promotion (old active becomes previous)
    "candidate-promote": "bash deploy/scripts/orchestrator-promote.sh --region us-west-2",
    // ğŸ—ï¸ Infrastructure: Sync .env file with Terraform state (interactive)
    "infra:sync-env": "cd infra && bash sync-env-from-terraform.sh",
    // ğŸ—ï¸ Infrastructure: Sync .env file with Terraform state (skip confirmation)
    "infra:sync-env:force": "cd infra && bash sync-env-from-terraform.sh --force",
    // Housekeeping: prune old images across Docker Hub and ECR (retain 6) (Terraform expires them past counts anyway)
    "images:cleanup": "bash ./scripts/image-cleanup.sh --retain 3 --include-untagged --login --profile bb-portfolio-user --region us-west-2",
    // Dry-run cleanup: show what would be removed without deleting
    "images:cleanup:dry-run": "bash ./scripts/image-cleanup.sh --retain 3 --include-untagged --login --profile bb-portfolio-user --region us-west-2 --dry-run",
    // ECR-only cleanup: prune old images (retain 6)
    "images:cleanup:ecr": "bash ./scripts/image-cleanup-ecr.sh --retain 3 --include-untagged",
    // ECR-only cleanup (dry run)
    "images:cleanup:ecr:dry-run": "bash ./scripts/image-cleanup-ecr.sh --retain 3 --include-untagged --dry-run",
    // Same as images:cleanup, but performs AWS/ECR login explicitly first
    "images:cleanup:login": "bash ./scripts/image-cleanup.sh --retain 3 --include-untagged --login --profile bb-portfolio-user --region us-west-2",
    // Verify image tags and counts in Docker Hub and ECR
    "images:verify": "bash ./scripts/images-verify.sh",
    // Verify counts after logging into AWS/ECR (useful on fresh shells)
    "images:verify:login": "bash ./scripts/images-verify.sh --login --profile bb-portfolio-user --region us-west-2",
    // ğŸ” Sync dev and main branches (fast-forward only, always returns to dev)
    "sync:branches": "bash ./scripts/sync-branches.sh",
    // âš¡ Fast repo search using ripgrep (pass pattern after `--`)
    "search:repo": "rg --line-number --hidden --follow --glob '!.git' --glob '!node_modules' --glob '!frontend/.next' --glob '!backend/.next'",
    // ğŸ“„ Quickly list files matching glob filters (shares ignore rules above)
    "search:files": "rg --files --hidden --follow --glob '!.git' --glob '!node_modules' --glob '!frontend/.next' --glob '!backend/.next'",
  },
  // Development tooling for the monorepo root (formatting, linting, TS, runners)
  "devDependencies": {
    // Next.js-specific ESLint rules for best practices
    "@next/eslint-plugin-next": "^16.0.10",
    // TypeScript type definitions for glob
    "@types/glob": "^9.0.0",
    // ESLint plugin for TypeScript-specific linting rules
    "@typescript-eslint/eslint-plugin": "^8.49.0",
    // TypeScript parser for ESLint
    "@typescript-eslint/parser": "^8.49.0",
    //
    "baseline-browser-mapping": "^2.9.7",
    // Run multiple commands concurrently in scripts
    "concurrently": "^9.2.1",
    // Main linter for JS/TS code
    "eslint": "^9.39.2",
    // ESLint plugin for import/export syntax validation
    "eslint-plugin-import": "^2.32.0",
    // ESLint plugin for React hooks rules
    "eslint-plugin-react-hooks": "^7.0.1",
    // ESLint plugin for React Fast Refresh support
    "eslint-plugin-react-refresh": "^0.4.25",
    // File pattern matching utility
    "glob": "^13.0.0",
    // List of global variables for linting
    "globals": "^16.5.0",
    // Utility for .gitignore-style file filtering
    "ignore": "^7.0.5",
    // Runtime for dynamic JS/TS imports
    "jiti": "^2.6.1",
    // JSON5 parser for annotated config files
    "json5": "^2.2.3",
    // Code formatter for consistent style
    "prettier": "^3.7.4",
    // TypeScript execution environment for scripts
    "ts-node": "^10.9.2",
    // TypeScript/ESM runner for scripts
    "tsx": "^4.21.0",
    // TypeScript language support
    "typescript": "^5.9.3",
  },
  // Root-level runtime deps used by maintenance scripts (prefer package-level deps when possible)
  "dependencies": {
    // JWT utilities used by local maintenance scripts
    "jsonwebtoken": "^9.0.3",
  },
}